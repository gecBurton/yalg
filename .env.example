# LLM Freeway Configuration Example

# Server Configuration
PORT=8000
BASE_URL=http://localhost:8000

# Database Configuration
DB_ENABLED=true
DB_HOST=localhost
DB_PORT=5432
DB_USER=llm_freeway
DB_PASSWORD=password
DB_NAME=llm_freeway
DB_SSLMODE=disable

# Authentication Configuration (OIDC)
OIDC_CLIENT_ID=your_client_id_here
OIDC_CLIENT_SECRET=your_client_secret_here
OIDC_REDIRECT_URI=http://localhost:8000/auth/callback

# Provider Configuration
AZURE_OPENAI_ENABLED=true
AZURE_OPENAI_API_KEY=your_azure_openai_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-01

OPENAI_ENABLED=true
OPENAI_API_KEY=your_openai_api_key

ANTHROPIC_ENABLED=true
ANTHROPIC_API_KEY=your_anthropic_api_key

AWS_REGION=us-east-1
# AWS credentials should be configured via AWS CLI or environment variables

GEMINI_ENABLED=true
GEMINI_API_KEY=your_gemini_api_key

# Metrics Configuration
METRICS_ENABLED=true
METRICS_RETENTION_DAYS=30